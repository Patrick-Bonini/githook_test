<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
  <head>
    <link href="../../Resources/TableStyles/Table_Num.css" rel="stylesheet" MadCap:stylesheetType="table"/>
    <link href="../../Resources/Stylesheets/MainStylesForReview.css" rel="stylesheet" type="text/css"/>
  </head>
  <body>
    <h1>Configuring Kafka Bridging</h1>
    <p>Kafka bridging enables Solace <MadCap:variable name="Product-Names.pubsub_brand_only"/> software event brokers to convert Solace messages that are placed in one or more queues into Kafka events and publish them to a remote Kafka cluster, and to consume Kafka events and publish them to a topic on the Solace event broker. For more information, see <MadCap:xref href="Kafka-Bridging-Overview.htm">Kafka Bridging Overview.</MadCap:xref></p>
    <p>To configure Kafka bridging, you need to create the following:</p>
    <ol>
      <li>
        <p>A Kafka receiver—receives events from one or more Kafka topics, converts the events to Solace messages, and publishes them in Solace Message Format (SMF) to topics on the <MadCap:variable name="Product-Names.pubsub_brand_only"/> event broker.</p>
      </li>
      <li>
        <p>A Kafka sender—takes SMF messages from one or more queues, converts the messages to Kafka events, and publishes them to Kafka topics on the remote Kafka cluster.</p>
      </li>
    </ol>
    <p>In addition, you may want to change the maximum number of simultaneous Kafka broker connections the event broker supports for the current Message VPN. For more information, see <MadCap:xref href="#Configur15">Configuring the Maximum Number of Kafka Broker Connections</MadCap:xref>.</p>
    <p>The following sections describe how to configure a Kafka receiver and a Kafka sender. For a detailed example that walks through all the steps required to set up a working Kafka bridge scenario, see <MadCap:xref href="Kafka-Bridging-Example.htm">Kafka Bridging Example.</MadCap:xref></p>
    <p>For instructions to configure Kafka bridging in <MadCap:variable name="Product-Names.pubsubmanager_long"/>, see <MadCap:xref href="../../Admin/Broker-Manager/config-kafka-bridge.htm" target="_blank">Configuring Kafka Bridging</MadCap:xref>.</p>
    <div class="Warning">Any Kafka bridging configuration made in BETA versions (earlier than 10.6.1) used in standalone deployments will be discarded upon upgrade to version 10.6.1 and later. In addition, you must remove any BETA Kafka bridging configuration used in a redundant (HA) deployment before attempting to upgrade to 10.6.1 or later.</div>
    <h2 class="with-rule"><a name="Configur14"/>Configuring a Kafka Receiver</h2>
    <p>On the event broker, the accumulation  and conversion of Kafka events to Solace messages is enabled by a Kafka receiver, which is configured at the Message VPN level. You can give the receiver any name. When you create a Kafka receiver for a Message VPN, the event broker automatically creates the following objects:</p>
    <ul>
      <li>
        <p>A single client for each Kafka receiver. This client publishes messages to the Solace message bus which have been received from the Kafka topics of all its topic bindings. This client's name is <code>#kafka/rx/&lt;rx-name&gt;</code>, and uses the client username <code>#kafka/rx/&lt;rx-name&gt;</code>. This client username uses the <code>#kafka</code> client profile and <code>#acl-profile</code> ACL profile.</p>
      </li>
      <li>
        <p>A single client-profile, called <code>#kafka</code>, which is needed for  all Kafka senders and receivers in the Message VPN. This profile is created when the first Kafka sender or receiver is created, and removed with the last Kafka sender or receiver.</p>
      </li>
    </ul>
    <p>
      <img src="../../Resources/Images/Kafka-Bridging/kafka_bridging_receiver_object_model.png" alt=""/>
    </p>
    <p>For more information, see <MadCap:xref href="Kafka-Bridging-Overview.htm#Kafka">Kafka Receiver</MadCap:xref>.</p>
    <p>To create a Kafka receiver, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure)# message-vpn &lt;name&gt;
solace(configure/message-vpn)# kafka
solace(configure/message-vpn/kafka)# create kafka-receiver &lt;name&gt;			</pre>
    <p>To configure an existing Kafka receiver:</p>
    <pre xml:space="preserve">solace(configure)# message-vpn &lt;name&gt;
solace(configure/message-vpn)# kafka
solace(configure/message-vpn/kafka)# kafka-receiver &lt;name&gt;			</pre>
    <p>To enable a Kafka receiver after it has been created:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver)# no shutdown</pre>
    <p><u>Where</u>:</p>
    <p><code>message-vpn &lt;name&gt;</code> is the name of the Message VPN where you want to create the Kafka receiver.</p>
    <p><code>kafka-receiver &lt;name&gt;</code> is the name of the Kafka receiver.</p>
    <p>The configuration tasks you can perform for a Kafka receiver include:</p>
    <ul>
      <li>
        <p>
          <MadCap:xref href="#Configur">Configuring  Authentication Schemes for Kafka Receivers</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Configur2">Configuring Message Batch Handling for Kafka Receivers</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Configur3">Configuring the Bootstrap Address List for Kafka Receivers</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Configur4">Configuring the Kafka Receiver Consumer Group</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Configur5">Configuring Kafka Topic Metadata Handling for Kafka Receivers</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Configur6">Configuring Topic Bindings for Kafka Receivers</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Enabling">Enabling TLS/SSL Encryption for Kafka Receiver Connections</MadCap:xref>
        </p>
      </li>
    </ul>
    <p> </p>
    <h3><a name="Configur"/>Configuring  Authentication Schemes for Kafka Receivers</h3>
    <p>To configure an authentication scheme that the given Kafka receiver will use to establish a connection to the remote Kafka cluster, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver)# authentication
solace(configure/message-vpn/kafka/kafka-receiver/authentication)# auth-scheme {none | basic | scram | client-certificate | kerberos | oauth-client}</pre>
    <p><u>Where</u>:</p>
    <p><code>none</code> specifies to login with no authentication. For more information, see <MadCap:xref href="#None">None</MadCap:xref>.</p>
    <p><code>basic</code> specifies to login with a username and  password. For more information, see <MadCap:xref href="#Basic">Basic Authentication</MadCap:xref>.</p>
    <p><code>scram</code> specifies to login with SCRAM (Salted Challenge Response Authentication). For more information, see <MadCap:xref href="#SCRAM">SCRAM Authentication.</MadCap:xref></p>
    <p><code>client-certificate</code> specifies to login with a client TLS certificate. For more information, see <MadCap:xref href="#Client">Client Certificate Authentication</MadCap:xref>.</p>
    <p><code>kerberos</code> specifies to login with the Kerberos mechanism. For more information, see <MadCap:xref href="#Kerberos">Kerberos Authentication</MadCap:xref>.</p>
    <p><code>oauth-client</code> specifies to login with OAuth 2.0 client credentials. For more information, see <MadCap:xref href="#OAuth">OAuth Client Authentication</MadCap:xref>.</p>
    <h4><a name="None"/>None</h4>
    <p>If no authentication scheme for a Kafka receiver is configured, the receiver will not use an authentication scheme. This may be useful for anonymous connections or when a Kafka receiver does not require authentication.</p>
    <h4><a name="Basic"/>Basic Authentication</h4>
    <p>Using the  basic authentication scheme, Kafka receivers can authenticate with a username and password combination. Credentials can either be transmitted using plain-text or encrypted with SSL.</p>
    <p>To configure settings for a basic authentication scheme, enter the following commands:</p>
    <pre xml:space="preserve">
solace(configure/message-vpn/kafka/kafka-receiver/authentication)# basic
solace(configure/message-vpn/kafka/kafka-receiver/authentication/basic)# username &lt;name&gt; [password &lt;password&gt;]</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;name&gt;</code> is the client username to use for authentication with the remote Kafka cluster. The username may contain up to 255 characters.</p>
    <p><code>&lt;password&gt;</code> is the  password to be used with the specified username. The password may contain up to 255 characters.</p>
    <p>The no version of the this command, <code>no username</code>, removes any configured   username and password.</p>
    <h4><a name="SCRAM"/>SCRAM Authentication</h4>
    <p>When using SCRAM authentication  (RFC 5802), a Kafka receiver uses a challenge/response mechanism to authenticate a username and password  with the remote Kafka cluster.  </p>
    <p>To configure settings for a SCRAM authentication scheme, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/authentication)# scram
solace(configure/message-vpn/kafka/kafka-receiver/authentication/scram)# hash {sha-256 | sha-512}
solace(configure/message-vpn/kafka/kafka-receiver/authentication/scram)# username &lt;name&gt; [password &lt;password&gt;]
</pre>
    <p><u>Where</u>:</p>
    <p><code>sha-256</code> specifies to use a SHA-2 256 bit hash for SCRAM authentication.</p>
    <p><code>sha-512</code> specifies to use SHA-2 512 bit hash for SCRAM authentication. This is the default setting. </p>
    <p><code>&lt;name&gt;</code> is the client username to use for authentication with the remote Kafka cluster. The username may contain up to 255 characters.</p>
    <p><code>&lt;password&gt;</code> is the password to be used with the specified username. The password may contain up to 255 characters.</p>
    <p>The no form of the <code>hash</code> command, <code>no hash</code>, returns the value to the default. </p>
    <p>The no form of the <code>username</code> command, <code>no username</code>, removes  any configured   username and password.</p>
    <h4><a name="Client"/>Client Certificate Authentication</h4>
    <p>When using client certificate authentication, a Kafka receiver provides a certificate file to validate its identity. Client certificate authentication is only available to connections that use TLS/SSL (see <MadCap:xref href="#Enabling">Enabling TLS/SSL Encryption for Kafka Receiver Connections</MadCap:xref>).</p>
    <p>The client certificate installed here may also be used if the Kafka cluster requests it with other authentication schemes. If you configure a client certificate authentication scheme for the Kafka receiver, the receiver provides only this client certificate as a means of identifying itself. However, it is possible to provide a client certificate when using a basic, SCRAM, or OAuth authentication scheme as well.</p>
    <p>To configure settings for a client certificate authentication scheme, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/authentication)# client-certificate
solace(configure/message-vpn/kafka/kafka-receiver/authentication/client-certificate)# certificate &lt;filename&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;filename&gt;</code> is the filename of the certificate file. The certificate file must be located in the <code>certs</code> folder of the event broker. Once a certificate is configured, a copy of it is saved internally. The file in the <code>certs</code> directory is no longer required. </p>
    <p>The no version of this command, <code>no certificate-file</code>, removes the certificate association for the current Kafka receiver.</p>
    <h4><a name="Kerberos"/>Kerberos Authentication</h4>
    <p>When using Kerberos authentication, a Kafka receiver must first authenticate with a Kerberos Authentication Server (AS) which grants the Kafka receiver a Ticket Granting Ticket (TGT).  With a valid TGT, a Kafka receiver can attempt to authenticate with the remote Kafka broker using a service ticket  obtained from the Ticket Granting Service (TGS). The AS and TGS (components of a Key Distribution Center (KDC)) are hosted on an external server or servers—not on the event broker.</p>
    <p>To implement Kerberos authentication for a Kafka receiver, you must configure the following:</p>
    <ol>
      <li>
        <p>The service name of the remote Kafka broker.</p>
      </li>
      <li>
        <p>The user principal name of the Kafka receiver.</p>
      </li>
      <li>
        <p>The keytab file for the Kafka receiver. </p>
      </li>
    </ol>
    <p class="Note">The  Kerberos realm (including KDC address) that this Kafka receiver  and the remote Kafka broker are part of must be configured before you can enable Kerberos authentication. For more information, see <MadCap:xref href="../../Security/Configuring-Client-Authentication.htm#Creating">Managing Kerberos Realms</MadCap:xref>.</p>
    <p>To configure these settings,  enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/authentication)# kerberos
solace(configure/message-vpn/kafka/kafka-receiver/authentication/kerberos)# service-name &lt;value&gt;
solace(configure/message-vpn/kafka/kafka-receiver/authentication/kerberos)# user-principal-name &lt;value&gt; &lt;keytab-file&gt;
</pre>
    <p><u>Where</u>:</p>
    <p><code>service-name &lt;value&gt;</code> is the Kerberos service name of the remote Kafka broker, not including <code>/hostname@&lt;REALM&gt;</code>.</p>
    <p><code>user-principal-name &lt;value&gt;</code> is the Kerberos user principal name of the Kafka receiver. This must include the <code>@&lt;REALM&gt;</code> suffix. </p>
    <p><code>&lt;keytab-file&gt;</code> is the filename of the Kerberos keytab file. The keytab file must be located in the <code>keytabs</code> folder of the event broker. These keytabs differ from those used in client authentication. Keytabs used for Kafka bridging authentication contain user principal names rather than service principal names, and apply to specific Message VPNs  rather than globally.</p>
    <h4><a name="OAuth"/>OAuth Client Authentication</h4>
    <p>When using OAuth client authentication, a Kafka receiver obtains access tokens from an authorization server using the Client Credentials Grant flow (RFC 6749 §4.4), also known as two-legged OAuth. In this flow, a simple  request with basic authentication is sent to the authorization server to get an access token. The Kafka receiver can then use the returned access token to make authenticated requests to the remote Kafka cluster until it expires (tokens are usually valid for an hour). When the token is near expiry, the Kafka consumer will automatically request another.</p>
    <p>To enable OAuth client authentication, you must configure the client ID, client secret, and token endpoint that the Kafka receiver will use to request access tokens. Optionally, you can also configure the OAuth scope.</p>
    <p>To configure these settings, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/authentication)# oauth-client
solace(configure/message-vpn/kafka/kafka-receiver/authentication/oauth-client)# client-id &lt;client-id&gt;
solace(configure/message-vpn/kafka/kafka-receiver/authentication/oauth-client)# client-secret &lt;client-secret&gt;
solace(configure/message-vpn/kafka/kafka-receiver/authentication/oauth-client)# token-endpoint &lt;token-endpoint&gt;
solace(configure/message-vpn/kafka/kafka-receiver/authentication/oauth-client)# scope &lt;scope&gt;
</pre>
    <p><u>Where</u>:</p>
    <p><code>client-id &lt;client-id&gt;</code> is the OAuth client ID the Kafka receiver uses to login to the authorization server when requesting access tokens. The OAuth client ID may contain up to 200 characters.</p>
    <p><code>client-secret &lt;client-secret&gt;</code> is the OAuth client secret the Kafka receiver uses to login to the authorization server when requesting access tokens. The OAuth client secret may contain up to 512 characters.</p>
    <p><code>token-endpoint &lt;token-endpoint&gt;</code> is the OAuth token endpoint URL that the Kafka receiver uses to request a token for login to the remote Kafka cluster. The OAuth token endpoint may contain up to 2048 characters. In addition, the token endpoint parameter must use TLS, that is, it must start with <code>https://</code> (case insensitive).</p>
    <p>(Optional) <code>scope &lt;scope&gt;</code> is the OAuth scope. The OAuth scope may contain up to 200 characters.</p>
    <h3><a name="Configur2"/>Configuring Message Batch Handling for Kafka Receivers</h3>
    <p>To configure the delay that the event broker waits before accumulating a batch of messages from the Kafka cluster, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver)# batch
solace(configure/message-vpn/kafka/kafka-receiver/batch)# delay &lt;ms&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;ms&gt;</code> specifies the delay in milliseconds to wait before accumulating a batch of messages from the Kafka cluster. The valid range of values is 0-300000. The default is 500. This corresponds to the <code>fetch.wait.max.ms</code> Kafka consumer API parameter. </p>
    <p>The no version of this command, <code>no delay</code>, resets the value to the default. </p>
    <p>To configure the maximum size of a message  batch, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver)# batch
solace(configure/message-vpn/kafka/kafka-receiver/batch)# max-size &lt;bytes&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;bytes&gt;</code> specifies the maximum  size of a message batch in bytes. The valid range of values is 1 to 100000000. the default is 1. This corresponds to the <code>fetch.min.bytes</code> Kafka consumer API parameter. </p>
    <p>The no version of this command, <code>no max-size</code>, resets the value to the default. </p>
    <h3><a name="Configur3"/>Configuring the Bootstrap Address List for Kafka Receivers</h3>
    <p>A bootstrap address  is the fully qualified domain name (FQDN) or IP address and optional port of one Kafka broker in a Kafka cluster where the Kafka receiver can fetch the state of the entire cluster. You can configure a list of these addresses for the Kafka receiver to try in the event that an attempt to connect to one address fails.   </p>
    <p>To configure the bootstrap address list for a Kafka receiver, enter the following command:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver)# bootstrap-addresses &lt;address-list&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;address-list&gt;</code> is a comma-separated list of FQDNs or addresses (and optional ports) of brokers in the Kafka cluster from which the state of the entire cluster can be learned. IPv4 addresses must be specified in the dotted decimal notation form, nnn.nnn.nnn.nnn.  IPv6  addresses must be enclosed in square brackets. The port is specified as a decimal value from 0 to 65535. For example, a correctly formatted IPv4 address is: <code>192.168.100.1:9092</code>. The same address in IPv6 format is <code>[::ffff:c0a8:6401]:9092</code>. This corresponds to the <code>bootstrap.servers</code> Kafka consumer API parameter. </p>
    <p class="Note">If a port is not provided with an address it will default
       to 9092.</p>
    <p>The no form of this command, <code>no bootstrap-addresses</code>, removes the bootstrap address list from the Kafka receiver. </p>
    <h3><a name="Configur4"/>Configuring the Kafka Receiver Consumer Group</h3>
    <p>Consumer groups allow Kafka consumers to work together and process Kafka events from a topic in parallel. Each consumer in the same group is assigned a different subset of partitions from a Kafka topic or set of topics. Depending on your deployment, you may want to specify certain details of the consumer group a Kafka receiver belongs to.  </p>
    <p>To configure the consumer group, enter the following command:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver)# group</pre>
    <p>The configuration tasks you can perform for a Kafka receiver consumer group include:</p>
    <ul>
      <li>
        <p>
          <MadCap:xref href="#ID">Configuring the Kafka Consumer Group ID for the Kafka Receiver</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Keepaliv">Configuring the Kafka Consumer Group Keepalive Settings</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Membersh">Configuring the Kafka Consumer Group Membership Type </MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Partitio">Configuring the Kafka Consumer Group Partition Scheme</MadCap:xref>
        </p>
      </li>
    </ul>
    <h4><a name="ID"/>Configuring the Kafka Consumer Group ID</h4>
    <p>To configure the Kafka consumer group ID for a Kafka receiver, enter the following command:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/group)# id &lt;value&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;value&gt;</code> specifies the ID. This corresponds to the <code>group.id</code> Kafka consumer API parameter. </p>
    <p>The no form of this command, <code>no id</code>, removes the consumer group ID specification.</p>
    <h4><a name="Keepaliv"/>Configuring the Kafka Consumer Group Keepalive Settings</h4>
    <p>To configure the keepalive interval for a Kafka consumer group, enter the following command:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/group)# interval &lt;ms&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;ms&gt;</code> specifies the time (in milliseconds) between sending keepalives to the group. The valid range of values is 1 to 3600000. The default is 3000. This corresponds to the <code>heartbeat.interval.ms</code> Kafka consumer API parameter. </p>
    <p>The no form of this command, <code>no interval</code>, resets the value to the default. </p>
    <p>To configure the keepalive timeout for a Kafka consumer group, enter the following command:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/group)# timeout &lt;ms&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;ms&gt;</code> specifies the time (in milliseconds) until unresponsive group members are removed, triggering a partition rebalance across other members of the group. The valid range of values is 1 to 3600000. The default is 45000. This corresponds to the <code>session.timeout.ms</code> Kafka consumer API parameter. </p>
    <p>The no form of this command, <code>no timeout</code>, resets the value to the default. </p>
    <h4><a name="Membersh"/>Configuring the Kafka Consumer Group Membership Type </h4>
    <p>To configure the membership type for a Kafka receiver consumer group, enter the following command:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/group)# membership-type {dynamic | static}</pre>
    <p><u>Where</u>:</p>
    <p><code>dynamic</code> specifies dynamic membership. This is the default. If the group membership type is <code>dynamic</code>, the Kafka consumer API parameter <code>group.instance.id</code> is empty. </p>
    <p><code>static</code> specifies static membership. Static members can leave and rejoin the group (within the configured keepalive timeout value) without prompting a group rebalance. If the group membership type is <code>static</code>, the Kafka consumer API parameter <code>group.instance.id</code> is set to string <code>&lt;broker-name&gt;/&lt;vpn-name&gt;/&lt;receiver-name&gt;</code>, where <code>&lt;broker-name&gt;</code> is the AD-enabled router name, <code>&lt;vpn-name&gt;</code> is the Message VPN name, and <code>&lt;receiver-name&gt;</code> is the Kafka receiver name. </p>
    <p>The no version of this command, <code>no membership-type</code>, resets the value to the default. </p>
    <h4><a name="Partitio"/>Configuring the Kafka Consumer Group Partition Scheme</h4>
    <p>To configure the partition scheme for a Kafka receiver consumer group, enter the following command:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/group)# partition-scheme &lt;partition-scheme-list&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;partition-scheme-list&gt;</code> is an ordered, comma-separated list of schemes for partition assignment of the consumer group for this receiver. Both Eager ("range, roundrobin") and Cooperative ("cooperative-sticky") schemes are supported. The elected group leader will choose the first common strategy provided by all members of the group. Eager and Cooperative schemes must not be mixed. For more information on these schemes, see the documentation for your Kafka implementation. The default partition scheme is ("range, roundrobin"). This corresponds to the <code>partition.assignment.strategy</code> Kafka consumer API parameter. </p>
    <p>The no version of this command, <code>no partition-scheme</code>, resets the value to the default. </p>
    <h3><a name="Configur5"/>Configuring Kafka Topic Metadata Handling for Kafka Receivers</h3>
    <p>To exclude certain topic metadata during refreshes, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver)# metadata
solace(configure/message-vpn/kafka/kafka-receiver/metadata)# topic
solace(configure/message-vpn/kafka/kafka-receiver/metadata/topic)# exclude &lt;regex-list&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;regex-list&gt;</code> is a comma-separated list of regular expressions (including POSIX.2 regular expressions). Any matching topic names will be ignored in the broker metadata. Note that each regular expression needs to start with the ^ character otherwise it will be interpreted as a literal topic name. </p>
    <p>The no form of this command, <code>no exclude</code>, removes all configured expressions. </p>
    <p>To configure the time between refreshes of topic metadata from the Kafka cluster, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver)# metadata
solace(configure/message-vpn/kafka/kafka-receiver/metadata)# topic
solace(configure/message-vpn/kafka/kafka-receiver/metadata/topic)# refresh-interval &lt;ms&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;ms&gt;</code> specifies the time (in milliseconds) between refreshes of topic metadata from the Kafka cluster. The valid range of values is 1000 to 3600000. the default is 30000. This corresponds to the <code>topic.metadata.refresh.interval.ms</code> Kafka consumer API parameter. </p>
    <p>The no form of this command, <code>no refresh-interval</code>, resets the value to the default. </p>
    <h3><a name="Configur6"/>Configuring Topic Bindings for Kafka Receivers</h3>
    <p>Each topic binding names the Kafka topic from which messages are drawn, and includes attributes which dictate how messages from that Kafka topic are to be sent to the Solace <MadCap:variable name="Product-Names.pubsub_brand_only"/> software event broker. </p>
    <p>To create a topic binding to receive messages from a remote Kafka topic, enter the following command:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver)# create topic-binding &lt;kafka-topic-or-regex&gt; </pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;kafka-topic-or-regex&gt;</code> is the name of the Kafka topic  you want this receiver to obtain messages from, or a regex pattern  (including POSIX.2 regular expressions) to receive from multiple Kafka topics. Note that each regular expression needs to start with the ^ character otherwise it will be interpreted as a literal topic name.</p>
    <p>To enable a topic binding, enter the following command:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/topic-binding)# no shutdown</pre>
    <p>The configuration tasks you can perform for a Kafka receiver topic binding include:</p>
    <ul>
      <li>
        <p>
          <MadCap:xref href="#Initial">Configuring the Initial Offset to Consume from the Kafka Topic</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Key">Configuring Kafka Partition to Partitioned Queue Key Mapping</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Topic">Configuring Kafka to SMF Topic Mapping</MadCap:xref>
        </p>
      </li>
    </ul>
    <h4><a name="Initial"/>Configuring the Initial Offset to Consume from the Kafka Topic</h4>
    <p>You can configure the initial offset that the Kafka receiver consumes from the Kafka topic if no member of the consumer group has consumed and committed any offset already, or if the last committed offset has been deleted. Offsets are unique per Kafka partition.</p>
    <p>To configure the initial offset that the Kafka receiver consumes from the Kafka topic, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/topic-binding)# initial-offset {beginning | end}
</pre>
    <p>
      <u>Where:</u>
    </p>
    <p><code>beginning</code> specifies to start with the earliest offset available. </p>
    <p><code>end</code> specifies to start with new offsets only. This is the default value. </p>
    <p>The initial offset corresponds to the <code>auto.offset.reset</code> Kafka consumer API parameter. </p>
    <p>The no form of this command, <code>no initial-offset</code>, resets the value to the default. </p>
    <h4><a name="Key"/>Configuring Partition  Key Generation</h4>
    <p>When messages are received from Kafka topics, you can configure the topic binding to generate a partition  key for each message. This is useful for determining which queue partition a  message is sent to. For more information, see <MadCap:xref href="../../Messaging/Guaranteed-Msg/Partitioned-Queue-Messaging.htm">Message Distribution With Partitioned Queues.</MadCap:xref> </p>
    <p>To configure how the topic binding generates a partition  key for each message received from a Kafka topic, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/topic-binding)# local
solace(configure/message-vpn/kafka/kafka-receiver/topic-binding/local)# key &lt;key-expression&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;key-expression&gt;</code> specifies the substitution expression used to generate the partition key for each message received from the Kafka topic. For more information, see <MadCap:xref href="../../Messaging/Substitution-Expressions-Overview.htm">Substitution Expressions</MadCap:xref>. If no value is configured, no key is included for each message as it is published into the event broker. </p>
    <h4><a name="Topic"/>Configuring SMF Topic Generation</h4>
    <p>When messages are received from Kafka topics they are published to SMF topics based on an expression you configure when you create a topic binding. </p>
    <p> To configure how the topic binding generates the SMF topic for each message received from a Kafka topic, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver/topic-binding)# local
solace(configure/message-vpn/kafka/kafka-receiver/topic-binding/local)# topic &lt;topic-expression&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;topic-expression&gt;</code> specifies the substitution expression used to generate the SMF topic for each message received from the Kafka topic. For more information, see <MadCap:xref href="../../Messaging/Substitution-Expressions-Overview.htm">Substitution Expressions Overview</MadCap:xref>. This expression can include data extracted from the metadata of each individual Kafka message as it is received from the Kafka Topic. If no value is configured, the Topic Binding will not be operational.  </p>
    <h3><a name="Enabling"/>Enabling TLS/SSL Encryption for Kafka Receiver Connections</h3>
    <p>To enable TLS/SSL encryption for Kakfa receiver connections, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-receiver)# transport
solace(configure/message-vpn/kafka/kafka-receiver/transport)# ssl</pre>
    <MadCap:snippetBlock src="../../Resources/Snippets/BrokerManager/KafkaReceiverEncryption.flsnp"/>
    <p>The no form of this command, <code>no ssl</code>, disables TLS/SSL encryption. </p>
    <h2 class="with-rule"><a name="Configur13"/>Configuring a Kafka Sender</h2>
    <p>On the event broker, conversion from Solace messages to Kafka events and propagation of those events to a remote Kafka cluster is enabled by a Kafka sender, which is configured at the Message VPN level. You can give the sender any name. When you create a Kafka sender for a Message VPN, the event broker automatically creates the following objects:</p>
    <ul>
      <li>
        <p>A single client for each Kafka sender. This client binds to the queues needed by the queue bindings of its sender. This client's name is <code>#kafka/tx/&lt;tx-name&gt;</code>, and uses the client username <code>#kafka/tx/&lt;tx-name&gt;</code>. This client username uses the <code>#kafka</code> client-profile and <code>#acl-profile</code> acl-profile.</p>
      </li>
      <li>
        <p>A single client-profile, called <code>#kafka</code>, which is needed for  all Kafka senders and receivers in the Message VPN. This profile is created when the first Kafka sender or receiver is created, and removed with the last Kafka sender or receiver.</p>
      </li>
    </ul>
    <p> </p>
    <p>
      <img src="../../Resources/Images/Kafka-Bridging/kafka_bridging_sender_object_model.png" alt=""/>
    </p>
    <p>For more information, see <MadCap:xref href="Kafka-Bridging-Overview.htm#Kafka2">Kafka Sender</MadCap:xref>.</p>
    <p>To create a Kafka sender, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure)# message-vpn &lt;name&gt;
solace(configure/message-vpn)# kafka
solace(configure/message-vpn/kafka)# create kafka-sender &lt;name&gt;			</pre>
    <p>To configure an existing Kafka sender:</p>
    <pre xml:space="preserve">solace(configure)# message-vpn &lt;name&gt;
solace(configure/message-vpn)# kafka
solace(configure/message-vpn/kafka)# kafka-sender &lt;name&gt;			</pre>
    <p>To enable a Kafka sender after it has been created:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender)# no shutdown</pre>
    <p><u>Where</u>:</p>
    <p><code>message-vpn &lt;name&gt;</code> is the name of the Message VPN where you want to create the Kafka sender.</p>
    <p><code>kafka-sender &lt;name&gt;</code> is the name of the Kafka sender.</p>
    <p>The configuration tasks you can perform for a Kafka sender include:</p>
    <ul>
      <li>
        <p>
          <MadCap:xref href="#Configur7">Configuring Authentication Schemes for Kafka Senders</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Configur8">Configuring Batching for Kafka Senders</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Configur9">Configuring the Bootstrap Address for Kafka Senders</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Configur10">Configuring Compression for Kafka Sender Connections</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Enabling2">Enabling Idempotence for Kafka Senders</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Configur11">Configuring Queue Bindings for Kafka Senders</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Enabling3">Enabling TLS/SSL Encryption for Kafka Sender Connections</MadCap:xref>
        </p>
      </li>
    </ul>
    <h3><a name="Configur7"/>Configuring Authentication Schemes for Kafka Senders</h3>
    <p>To configure an authentication scheme that the given Kafka sender will use to establish a connection to the remote Kafka cluster, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender)# authentication
solace(configure/message-vpn/kafka/kafka-sender/authentication)# auth-scheme {none | basic | scram | client-certificate | kerberos | oauth-client}</pre>
    <p><u>Where</u>:</p>
    <p><code>none</code> specifies to login with no authentication. For more information, see <MadCap:xref href="#None2">None</MadCap:xref>.</p>
    <p><code>basic</code> specifies to login with a username and password. For more information, see <MadCap:xref href="#Basic2">Basic Authentication</MadCap:xref>.</p>
    <p><code>scram</code> specifies to login with SCRAM (Salted Challenge Response Authentication). For more information, see <MadCap:xref href="#SCRAM2">SCRAM Authentication</MadCap:xref></p>
    <p><code>client-certificate</code> specifies to login with a client TLS certificate. For more information, see <MadCap:xref href="#Client2">Client Certificate Authentication</MadCap:xref>.</p>
    <p><code>kerberos</code> specifies to login with the Kerberos mechanism. For more information, see <MadCap:xref href="#Kerberos2">Kerberos Authentication</MadCap:xref>.</p>
    <p><code>oauth-client</code> specifies to login with OAuth 2.0 client credentials. For more information, see <MadCap:xref href="#OAuth2">OAuth Client Authentication</MadCap:xref>.</p>
    <h4><a name="None2"/>None</h4>
    <p>If no authentication scheme for a Kafka sender is configured, the sender will not use an authentication scheme. This may be useful for anonymous connections or when a Kafka sender does not require authentication.</p>
    <h4><a name="Basic2"/>Basic Authentication</h4>
    <p>Using the  basic authentication scheme, Kafka senders can authenticate with a username and password combination. Credentials can either be transmitted using plain-text or encrypted with SSL.</p>
    <p>To configure settings for a basic authentication scheme, enter the following commands:</p>
    <pre xml:space="preserve">
solace(configure/message-vpn/kafka/kafka-sender/authentication)# basic
solace(configure/message-vpn/kafka/kafka-sender/authentication/basic)# username &lt;name&gt; [password &lt;password&gt;]</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;name&gt;</code> is the client username to use for authentication with the remote Kafka cluster. The username may contain up to 255 characters.</p>
    <p><code>&lt;password&gt;</code> is the password to be used with the specified username. The password may contain up to 255 characters.</p>
    <p>The no version of the this command, <code>no username</code>, removes any configured   username and password.</p>
    <h4><a name="SCRAM2"/>SCRAM Authentication</h4>
    <p>When using SCRAM authentication  (RFC 5802), a Kafka sender uses a challenge/response mechanism to authenticate a username and password  with the remote Kafka cluster.  </p>
    <p>To configure settings for a SCRAM authentication scheme, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender/authentication)# scram
solace(configure/message-vpn/kafka/kafka-sender/authentication/scram)# hash {sha-256 | sha-512}
solace(configure/message-vpn/kafka/kafka-sender/authentication/scram)# username &lt;name&gt; [password &lt;password&gt;]
</pre>
    <p><u>Where</u>:</p>
    <p><code>sha-256</code> specifies to use a SHA-2 256 bit hash for SCRAM authentication.</p>
    <p><code>sha-512</code> specifies to use SHA-2 512 bit hash for SCRAM authentication. This is the default setting. </p>
    <p><code>&lt;name&gt;</code> is the client username to use for authentication with the remote Kafka cluster. The username may contain up to 255 characters.</p>
    <p><code>&lt;password&gt;</code> is the password to be used with the specified username. The password may contain up to 255 characters.</p>
    <p>The no form of the <code>hash</code> command, <code>no hash</code>, returns the value to the default. </p>
    <p>The no form of the <code>username</code> command, <code>no username</code>, removes  any configured   username and password.</p>
    <h4><a name="Client2"/>Client Certificate Authentication</h4>
    <p>When using client certificate authentication, a Kafka sender provides a certificate file to validate its identity. Client certificate authentication is only available to connections that use TLS/SSL (see <MadCap:xref href="#Enabling">Enabling TLS/SSL Encryption for Kafka Receiver Connections</MadCap:xref>).</p>
    <p>The client certificate installed here may also be used if the Kafka cluster requests it with other authentication schemes. If you configure a client certificate authentication scheme for the Kafka sender, the sender provides only this client certificate as a means if identifying itself. However, it is possible to provide a client certificate when using a basic or SCRAM authentication scheme as well.</p>
    <p>To configure settings for a client certificate authentication scheme, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender/authentication)# client-certificate
solace(configure/message-vpn/kafka/kafka-sender/authentication/client-certificate)# certificate &lt;filename&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;filename&gt;</code> is the filename of the certificate file. The certificate file must be located in the <code>certs</code> folder of the event broker. Once a certificate is configured, a copy of it is saved internally. The file in the <code>certs</code> directory is no longer required.</p>
    <p>The no version of this command, <code>no certificate-file</code>, removes the certificate association for the current Kafka sender.</p>
    <h4><a name="Kerberos2"/>Kerberos Authentication</h4>
    <p>When using Kerberos authentication, a Kafka sender must first authenticate with a Kerberos Authentication Server (AS) which grants the Kafka sender a Ticket Granting Ticket (TGT).  With a valid TGT, a Kafka sender can attempt to authenticate with the remote Kafka broker using a service ticket  obtained from the Ticket Granting Service (TGS). The AS and TGS (components of a Key Distribution Center (KDC)) are hosted on an external server or servers—not on the event broker.</p>
    <p>To implement Kerberos authentication for a Kafka sender, you must configure the following:</p>
    <ol>
      <li>
        <p>The service name of the remote Kafka broker.</p>
      </li>
      <li>
        <p>The user principal name of the Kafka sender.</p>
      </li>
      <li>
        <p>The keytab file for the Kafka sender. </p>
      </li>
    </ol>
    <p class="Note">The  Kerberos realm (including KDC address) that this Kafka sender  and the remote Kafka broker are part of must be configured before you can enable Kerberos authentication. For more information, see <MadCap:xref href="../../Security/Configuring-Client-Authentication.htm#Creating">Managing Kerberos Realms</MadCap:xref>.</p>
    <p>To configure these settings,  enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender/authentication)# kerberos
solace(configure/message-vpn/kafka/kafka-sender/authentication/kerberos)# service-name &lt;value&gt;
solace(configure/message-vpn/kafka/kafka-sender/authentication/kerberos)# user-principal-name &lt;value&gt; &lt;keytab-file&gt;
</pre>
    <p><u>Where</u>:</p>
    <p><code>service-name &lt;value&gt;</code> is the Kerberos service name of the remote Kafka broker, not including <code>/hostname@&lt;REALM&gt;</code>.</p>
    <p><code>user-principal-name &lt;value&gt;</code> is the Kerberos user principal name of the Kafka sender. This must include the <code>@&lt;REALM&gt;</code> suffix. </p>
    <p><code>&lt;keytab-file&gt;</code> is the filename of the Kerberos keytab file. The keytab file must be located in the <code>keytabs</code> folder of the event broker. These keytabs differ from those used in client authentication. Keytabs used for Kafka bridging authentication contain user principal names rather than service principal names, and apply to specific Message VPNs  rather than globally.</p>
    <h4><a name="OAuth2"/>OAuth Client Authentication</h4>
    <p>When using OAuth client authentication, a Kafka sender obtains access tokens from an authorization server using the Client Credentials Grant flow (RFC 6749 §4.4), also known as two-legged OAuth. In this flow, a simple request with basic authentication is sent to the authorization server to get an access token. The Kafka sender can then use the returned access token to make authenticated requests to the remote Kafka cluster until it expires (tokens are usually valid for an hour). When the token is near expiry, the Kafka sender will automatically request another.</p>
    <p>To enable OAuth client authentication, you must configure the client ID, client secret, and token endpoint that the Kafka sender will use to request access tokens. Optionally, you can also configure the OAuth scope.</p>
    <p>To configure these settings, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender/authentication)# oauth-client
solace(configure/message-vpn/kafka/kafka-sender/authentication/oauth-client)# client-id &lt;client-id&gt;
solace(configure/message-vpn/kafka/kafka-sender/authentication/oauth-client)# client-secret &lt;client-secret&gt;
solace(configure/message-vpn/kafka/kafka-sender/authentication/oauth-client)# token-endpoint &lt;token-endpoint&gt;
solace(configure/message-vpn/kafka/kafka-sender/authentication/oauth-client)# scope &lt;scope&gt;
</pre>
    <p><u>Where</u>:</p>
    <p><code>client-id &lt;client-id&gt;</code> is the OAuth client ID the Kafka sender uses to login to the authorization server when requesting access tokens. The OAuth client ID may contain up to 200 characters.</p>
    <p><code>client-secret &lt;client-secret&gt;</code> is the OAuth client secret the Kafka sender uses to login to the authorization server when requesting access tokens. The OAuth client secret may contain up to 512 characters.</p>
    <p><code>token-endpoint &lt;token-endpoint&gt;</code> is the OAuth token endpoint URL that the Kafka sender uses to request a token for login to the remote Kafka cluster. The OAuth token endpoint may contain up to 2048 characters. In addition, the token endpoint parameter must use TLS, that is, it must start with <code>https://</code> (case insensitive).</p>
    <p>(Optional) <code>scope &lt;scope&gt;</code> is the OAuth scope. The OAuth scope may contain up to 200 characters.</p>
    <h3><a name="Configur8"/>Configuring Message Batch Handling for Kafka Senders</h3>
    <p>To configure the delay that the Kafka sender waits before accumulating a batch of messages to send to the Kafka cluster, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender)# batch
solace(configure/message-vpn/kafka/kafka-sender/batch)# delay &lt;ms&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;ms&gt;</code> specifies the delay in milliseconds to wait before accumulating a batch of messages to send to the Kafka cluster. The valid range of values is 0 to 90000. The default is 5. This corresponds to the <code>queue.buffering.max.ms</code> Kafka producer API parameter. </p>
    <p>The no version of this command, <code>no delay</code>, resets the value to the default. </p>
    <p>To configure the maximum number of messages in a batch, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender)# batch
solace(configure/message-vpn/kafka/kafka-sender/batch)# max-messages &lt;count&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;count&gt;</code> specifies the maximum number of messages to send to the Kafka cluster in a single batch. The valid range of values is 1 to 1000000. The default is 10000. This corresponds to the <code>batch.num.messages</code> Kafka producer API parameter. </p>
    <p>The no version of this command, <code>no max-messages</code>, resets the value to the default. </p>
    <p>To configure the maximum size of a message  batch, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender)# batch
solace(configure/message-vpn/kafka/kafka-sender/batch)# max-size &lt;bytes&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;bytes&gt;</code> specifies the maximum message size of a message batch in bytes. The valid range of values is 1 to 2147483647. the default is 1000000. This corresponds to the <code>batch.size</code> Kafka producer API parameter. </p>
    <p>The no version of this command, <code>no max-size</code>, resets the value to the default.</p>
    <h3><a name="Configur9"/>Configuring the Bootstrap Address List for Kafka Senders</h3>
    <p>A bootstrap address  is the fully qualified domain name or IP address and optional port of one Kafka broker in a Kafka cluster where the Kafka sender can fetch the state of the entire cluster. You can configure a list of these addresses for the Kafka sender to try in the event that an attempt to connect to one address fails.   </p>
    <p>To configure the bootstrap address list for a Kafka sender, enter the following command:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender)# bootstrap-addresses &lt;address-list&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;address-list&gt;</code> is a comma-separated list of FQDNs or addresses (and optional ports) of brokers in the Kafka cluster from which the state of the entire cluster can be learned. IPv4 addresses must be specified in the dotted decimal notation form, nnn.nnn.nnn.nnn.  IPv6  addresses must be enclosed in square brackets. The port is specified as a decimal value from 0 to 65535. For example, a correctly formatted IPv4 address is: <code>192.168.100.1:9092</code>. The same address in IPv6 format is <code>[::ffff:c0a8:6401]:9092</code>. This corresponds to the <code>bootstrap.servers</code> Kafka producer API parameter.</p>
    <p class="Note">If a port is not provided with an address it will default
       to 9092.</p>
    <p>The no form of this command, <code>no bootstrap-addresses</code>, removes the bootstrap address list from the Kafka sender.</p>
    <h3><a name="Configur10"/>Configuring Compression for Kafka Senders</h3>
    <p>To configure the compression type the Kafka sender uses when propagating messages, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender)# compression
solace(configure/message-vpn/kafka/kafka-sender/compression)# type {gzip | snappy | lz4 | zstd}</pre>
    <p><u>Where</u>:</p>
    <p><code>gzip</code> specifies to use Gzip compression. This is the default.</p>
    <p><code>snappy</code> specifies to use Snappy compression.</p>
    <p><code>lz4</code> specifies to use LZ4 compression.</p>
    <p><code>zstd</code> specifies to use Zstandard compression.</p>
    <p>The compression type corresponds to the <code>compression.codec</code> Kafka producer API parameter. </p>
    <p>The no version of this command, <code>no compression</code>, resets the value to the default. </p>
    <p>To configure the compression level the Kafka sender uses when propagating messages, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender)# compression
solace(configure/message-vpn/kafka/kafka-sender/compression)# level </pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;value&gt;</code> specifies the compression level. The valid range of values depends on the compression type:</p>
    <p>The compression level corresponds to the <code>compression.level</code> Kafka producer API parameter. </p>
    <p>The no version of this command, <code>no compression</code>, resets the value to the default.</p>
    <ul>
      <li>
        <p><code>-1</code> means use the codec-dependent default compression level and is always valid. This is the default. </p>
      </li>
      <li>
        <p><code>0</code>-<code>9</code> is valid for the <code>gzip</code> compression codec. </p>
      </li>
      <li>
        <p><code>0</code> is valid for the <code>snappy</code> compression codec. </p>
      </li>
      <li>
        <p><code>0</code>-<code>12</code> is valid for the <code>lz4</code> compression codec.</p>
      </li>
      <li>
        <p><code>0</code>-<code>22</code> is valid for the <code>zstd</code> compression codec.</p>
      </li>
    </ul>
    <p>To enable compression, see <MadCap:xref href="#Enabling4">Enabling Compression for Kafka Sender Connections</MadCap:xref>.</p>
    <div class="Caution">
      <p>A Kafka sender is blocked from being operational if you configure it  to use both encryption and compression, while <code>crime-exploit-protection</code> is enabled (see <MadCap:xref href="../../Security/Configuring-CRIME-Exploit-Protect.htm">Configuring CRIME Exploit Protection</MadCap:xref>).</p>
    </div>
    <h3><a name="Enabling2"/>Enabling Idempotence for Kafka Senders</h3>
    <p>Idempotence guarantees in order at-least-once message delivery to the remote Kafka topic, at the expense of performance. It is disabled by default. If you enable idempotence, each queue binding configured for the Kafka sender must have the acknowledgment mode set to <code>all</code> to be operational.</p>
    <p>To enable idempotence for a Kafka sender, enter the following command:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender)# idempotence
</pre>
    <p>This corresponds to the <code>enable.idempotence</code> Kafka producer API parameter. </p>
    <p>The no version of this command, <code>no idempotence</code> disables it. </p>
    <MadCap:snippetBlock src="../../Resources/Snippets/BrokerManager/kafka-imdepotence.flsnp"/>
    <h3><a name="Configur11"/>Configuring Queue Bindings for Kafka Senders</h3>
    <p>Each binding names the queue from which messages are drawn, and includes attributes which dictate how those messages are to be sent to Kafka.</p>
    <p>To create a queue binding for a Kafka sender, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender)# create queue-binding &lt;queue-name&gt;</pre>
    <p>To enable a queue binding:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender/queue-binding)# no shutdown</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;queue-name&gt;</code> is the name of a queue in the given Message VPN that the Kafka sender binds to. </p>
    <p>The configuring tasks you can perform for a Kafka sender queue binding include:</p>
    <ul>
      <li>
        <p>
          <MadCap:xref href="#ACK">Configuring the Acknowledgment Mode</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Partitio2">Configuring the Kafka Partition Selection Scheme</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Remote">Configuring Partitioned Queue to Kafka Partition Key Mapping</MadCap:xref>
        </p>
      </li>
      <li>
        <p>
          <MadCap:xref href="#Configur12">Configuring SMF to Kafka Topic Mapping</MadCap:xref>
        </p>
      </li>
    </ul>
    <h4><a name="ACK"/>Configuring the Acknowledgment Mode</h4>
    <p>To configure the number of acknowledgments that this queue binding requires from the remote Kafka cluster, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender/queue-binding)# ack-mode {none | one | all}</pre>
    <p><u>Where</u>:</p>
    <p><code>none</code> specifies that no acknowledgements from the remote Kafka cluster are required. If configured, messages are delivered at-most-once.</p>
    <p><code>one</code>  specifies that one acknowledgement from the remote Kafka cluster is required. If configured, messages  are delivered at-least-once but may be reordered. </p>
    <p><code>all</code>  specifies that all replicas on the remote Kafka cluster need to acknowledge the message. If configured, messages  are delivered at-least-once but may be reordered. This is the default setting.</p>
    <p>The acknowledgment mode corresponds to the <code>request.required.acks</code> Kafka producer API parameter. </p>
    <p>The no form of this command, <code>no ack-mode</code>, resets the value to the default. </p>
    <h4><a name="Partitio2"/>Configuring the Kafka Partition Selection Scheme</h4>
    <p>To configure the partition selection scheme that the given queue binding will use when publishing to the remote Kafka cluster, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender/queue-binding)# partition
solace(configure/message-vpn/kafka/kafka-sender/queue-binding/partition)# scheme {consistent | explicit | random}</pre>
    <p><u>Where</u>:</p>
    <p><code>consistent</code> specifies to use a consistent partition selection scheme. For more information, see <MadCap:xref href="#Consiste">Consistent Partition Selection</MadCap:xref>.</p>
    <p><code>explicit</code> specifies to use an explicit partition selection scheme. For more information, see <MadCap:xref href="#Explicit">Explicit Partition Selection</MadCap:xref>.</p>
    <p><code>random</code> specifies to use a random partition selection scheme. For more information, see <MadCap:xref href="#Random">Random Partition Selection</MadCap:xref>.</p>
    <h4><a name="Consiste"/>Consistent Partition Selection</h4>
    <p>When using a consistent partition selection scheme, the queue binding selects a Kafka partition based on a hash of the Kafka partition key generated by the Kafka sender (see <MadCap:xref href="#Remote">Configuring Kafka Partition Key Generation</MadCap:xref>). If no key is available for the message, by default, a random selection scheme is used as a fallback. You can disable this fallback, and if you do a single partition is selected for all unkeyed messages (see <MadCap:xref href="#Random">Random Partition Selection</MadCap:xref>). </p>
    <p>To configure the hash algorithm used to select the partition, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender/queue-binding)# partition
solace(configure/message-vpn/kafka/kafka-sender/queue-binding/partition)# consistent 
solace(configure/message-vpn/kafka/kafka-sender/queue-binding/partition/consistent)# hash {crc | murmur2 | fnv1a}</pre>
    <p><u>Where</u>:</p>
    <p><code>crc</code> specifies to use CRC Hash. This is the default setting. </p>
    <p><code>murmur2</code> specifies to use Murmur2 Hash.</p>
    <p><code>fnv1a</code> specifies to use Fowler-Noll-Vo 1a Hash.</p>
    <p>The no version of this command, <code>no hash</code>, resets the value to the default. </p>
    <h4><a name="Explicit"/>Explicit Partition Selection</h4>
    <p>When using an explicit partition selection scheme, the queue binding selects a  Kafka partition based explicitly on the number you specify. </p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender/queue-binding)# partition
solace(configure/message-vpn/kafka/kafka-sender/queue-binding/partition)# explicit 
solace(configure/message-vpn/kafka/kafka-sender/queue-binding/partition/explicit)# number &lt;value&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;value&gt;</code> is the Kafka partition number you want the queue binding to use when publishing messages. </p>
    <p>The no version of this command, <code>no number</code>, resets the value to the default. </p>
    <h4><a name="Random"/>Random Partition Selection</h4>
    <p>When using a random partition selection scheme, the queue binding selects a random Kafka partition. By default, this partition selection scheme is used as a fallback in cases where a consistent partition selection scheme is being used but no partition key is available for the message. If you disable this fallback, a single partition is selected for all unkeyed messages.</p>
    <p>To disable random partition selection as a fallback, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender/queue-binding)# partition
solace(configure/message-vpn/kafka/kafka-sender/queue-binding/partition)# random 
solace(configure/message-vpn/kafka/kafka-sender/queue-binding/partition/random)# no fallback</pre>
    <p>To enable  the fallback if disabled, enter the following command. </p>
    <pre xml:space="preserve">
solace(configure/message-vpn/kafka/kafka-sender/queue-binding/partition/random)# fallback</pre>
    <h4><a name="Remote"/>Configuring Kafka Partition Key Generation</h4>
    <p>To configure how the queue binding generates Kafka partition keys for each message sent to the remote Kafka cluster, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender/queue-binding)# remote
solace(configure/message-vpn/kafka/kafka-sender/queue-binding/remote)# key &lt;key-expression&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;key-expression&gt;</code> specifies the substitution expression used to generate the Kafka partition key for each message sent to Kafka. For more information about substitution expressions, see <MadCap:xref href="../../Messaging/Substitution-Expressions-Overview.htm">Substitution Expressions</MadCap:xref>. This expression can include fields extracted from the metadata of each individual SMF message as it is taken from the  queue. If empty, no key is included for each message as it is published into Kafka.  </p>
    <h4><a name="Configur12"/>Configuring SMF to Kafka Topic Mapping</h4>
    <p>To configure the topic on the Kafka cluster that this queue binding sends each message to, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender/queue-binding)# remote 
solace(configure/message-vpn/kafka/kafka-sender/queue-binding/remote)# topic &lt;kafka-topic&gt;</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;kafka-topic&gt;</code> is the Kafka topic on the Kafka cluster to send each message taken from the queue to. If no topic  is configured, the queue binding will not be operational. </p>
    <h3><a name="Enabling3"/>Enabling TLS/SSL Encryption for Kafka Sender Connections</h3>
    <p>To enable TLS/SSL encryption for Kakfa sender connections, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender)# transport
solace(configure/message-vpn/kafka/kafka-sender/transport)# ssl</pre>
    <p>For more information describing how the combination of TLS/SSL encryption and authentication scheme settings correspond to the <code>security.protocol</code> Kafka producer API parameter, see <MadCap:xref href="#Enabling">Enabling TLS/SSL Encryption for Kafka Receiver Connections</MadCap:xref>.</p>
    <p>The no form of this command, <code>no ssl</code>, disables TLS/SSL encryption. </p>
    <h3><a name="Enabling4"/>Enabling Compression for Kafka Sender Connections</h3>
    <p>By default, Kafka sender connections do not have compression enabled. You can enable compression according to the type and level configured for the sender (see <MadCap:xref href="#Configur10">Configuring Compression for Kafka Sender Connections</MadCap:xref>).</p>
    <p>To enable compression for Kafka sender connections, enter the following commands:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka/kafka-sender)# transport
solace(configure/message-vpn/kafka/kafka-sender/transport)# compressed</pre>
    <p>The no form of this command, <code>no compressed</code>, disables compression. </p>
    <h2 class="with-rule"><a name="Configur15"/>Configuring the Maximum Number of Kafka Broker Connections</h2>
    <p>By default, the maximum number of Kafka broker connections supported for a Message VPN is the same as the maximum supported for the system. Depending on your deployment, you may want to change this behavior so that one Message VPN does not consume  all of the connections that the entire system supports.</p>
    <p>To configure the maximum number of simultaneous Kafka broker connections for this Message VPN, enter the following command:</p>
    <pre xml:space="preserve">solace(configure/message-vpn/kafka)# max-broker-connections &lt;value&gt;
</pre>
    <p><u>Where</u>:</p>
    <p><code>&lt;value&gt;</code> is the integer value specifying the maximum total number of Kafka broker connections permitted for the Message VPN. </p>
    <p>the no version of this command, <code>no max-broker-connections</code>, returns the value to the default (which is the maximum value supported by the platform). </p>
    <div class="Note">
      <ul>
        <li>To view the maximum total number of Kafka broker connections that the Solace PubSub+ event broker can support, enter the <code>show kafka</code> User EXEC command.</li>
        <li>This is a global/read-write parameter, and is chosen by the system administrator, not the Message VPN administrator.</li>
      </ul>
    </div>
  </body>
</html>
