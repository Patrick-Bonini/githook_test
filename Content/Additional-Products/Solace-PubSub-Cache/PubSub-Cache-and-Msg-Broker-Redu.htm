<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
  <head/>
  <body>
    <h1><MadCap:variable name="Product-Names.pubsub_cache"/> and Event Broker Redundancy</h1>
    <p><MadCap:variable name="Product-Names.pubsub_cache"/> is designed to provide redundancy through instantiating multiple cache instances for each cluster. Any number of cache instances may be provisioned across multiple servers and locations to achieve the desired protection from a single network event affecting the entire cluster. <MadCap:variable name="Variables.CompanyName"/> recommends that for each cluster, you connect at least one cache instance to each active broker in the mesh.</p>
    <p><MadCap:variable name="Product-Names.pubsub_cache"/> is a Direct messaging service. Unless you need Guaranteed messaging for other applications that are using the same brokers that <MadCap:variable name="Product-Names.pubsub_cache"/> connects to, there is no advantage to deploying the brokers as high-availability (HA) pairs. But if you need to support Guaranteed messaging alongside your Direct messaging applications using <MadCap:variable name="Product-Names.pubsub_cache"/>, then you will want to deploy your brokers in HA pairs. In that case, you will need to choose between the active/standby and active/active redundancy models.</p>
    <p class="Note">Active/active redundancy applies only to Direct messaging in the broker. Guaranteed messaging is always active/standby regardless of the redundancy model chosen.</p>
    <p>HA pairing of brokers ensures that there is no loss of Guaranteed messages in the event of a broker failure. <b>Direct messaging and <MadCap:variable name="Product-Names.pubsub_cache"/> cannot offer the same delivery guarantees, even in an HA pair</b>. So while HA pairing of brokers ensures rapid restoration of service to publishers and consumers following an event broker failure,  any messages published to an event broker at the moment of its failure may not be delivered to some or all of the other brokers and cache instances in an event mesh. Furthermore, depending upon the redundancy model chosen, there may be additional messages published to the mesh that may not be delivered to one or more cache instances in the mesh while the failover is happening.</p>
    <p><MadCap:variable name="Product-Names.pubsub_cache"/> instances must communicate with a Cache Manager whenever they establish a connection to an event broker. Following this initial communication, cache instances are designed to tolerate loss of communication with the cache manager and are capable of continuing service to an event mesh of event brokers as long as they remain connected. So, assuming at least one cache instance per broker, a loss of cache manager connectivity does not result in an interruption or loss of caching services in the event mesh. </p>
    <p class="Note" MadCap:conditions="Default.HideFromAllOutput">For releases prior to 10.0.1, in all redundancy models except active/standby, administrative action may be required to restore cache manager services following a failover, since only one active broker in the mesh can be the designated cache manager. The <b>active/standby model</b> is the preferred (and only) solution if you are managing a distributed cache on a HA pair of brokers and if you are using a software event broker, or if you are using Dynamic Message Routing (DMR) to interconnect the event brokers into an event mesh. This approach provides administrative advantages in that if the failing broker was providing cache manager services,  the cache manager on the backup broker will be able to accept registration from cache instances immediately following a failover. It should be noted that following a failover, there will be a brief period of time before the newly-active broker has connectivity to at least one cache instance in the mesh. During that period, messages published to the newly-active broker will not be cached anywhere in the mesh, and cache requests from clients connecting to that broker will not receive cache responses. This means applications must be able to tolerate possible loss of cached messages and requests during and after a service affecting event on the active broker.</p>
    <p>Generally, only one event broker must be designated as a cache manager. However, for redundancy, you can designate an HA pair for cache management to follow activity, as it is redundancy aware. This applies to all redundancy models. </p>
    <p>The <b>active/standby model</b> is the preferred (and only) solution if you are managing a distributed cache on an HA pair of brokers and if you are using a software event broker, or if you are using Dynamic Message Routing (DMR) to interconnect the brokers into an event mesh. </p>
    <p>This approach provides administrative advantages in that if the failing broker was providing cache manager services,  the cache manager on the backup broker will be able to accept registration from cache instances immediately following a failover. </p>
    <p class="Note">Following a failover, there will be a brief period of time before the newly-active broker has connectivity to at least one cache instance in the event mesh. During that period, messages published to the newly-active broker will not be cached anywhere in the mesh, and cache requests from clients connecting to that broker will not receive cache responses. This means applications must be able to tolerate possible loss of cached messages and requests during and after a service affecting event on the active broker.</p>
    <p MadCap:conditions="Default.HideFromAllOutput">NOTES? It is common in configurations of <MadCap:variable name="Product-Names.pubsub_cache"/> to: </p>
    <ul MadCap:conditions="Default.HideFromAllOutput">
      <li>Disable stop-on-loss messages (see <MadCap:xref href="Configuring-PubSub-Cache-Ins.htm#Stop-On-Loss">Configuring Stop On Lost Message Behavior</MadCap:xref>).</li>
      <li>Disable auto start mode so that  PubSub+Cache instances do not automatically comes online whenever it restarts or reconnects to an event broker (see <MadCap:xref href="Configuring-PubSub-Cache-Ins.htm#Auto-Start">Enabling/Disabling Auto Start Mode</MadCap:xref>).</li>
    </ul>
    <p>Cache instances are able to immediately re-register with the active cache manager without administrative intervention because its availability follows the active broker in an HA pair for appliances (presuming stop-on-lost message is disabled).  For more information, see <MadCap:xref href="Configuring-PubSub-Cache-Ins.htm#Stop-On-Loss">Configuring Stop On Lost Message Behavior</MadCap:xref>.</p>
    <p>For <MadCap:variable name="Product-Names.broker_sw_short"/>s, cache instances can also immediately re-register with the cache manager of the active broker (without administrative intervention) if the use of hostlists ( the <code>SESSION_HOST</code> parameter) for each of the cache instances contain the IP address or hostname of both the primary and backup brokers in a high-availability (HA) redundancy group. The re-registration occurs provided that the valid when the configuration is adhered to as describe in the  <b>Active/Standby Redundancy Model</b> section in <MadCap:xref href="#Config-Summary">Configuration Summary</MadCap:xref>.</p>
    <p class="Note" MadCap:conditions="Default.HideFromAllOutput">For releases prior to 10.0.1, this approach may require administrative intervention to restore the cache management function if the failed broker was providing the cache management function. Any cache instances needing to restore a connection and registration to the cache cluster will be unable to do so until the failed broker comes back online and takes activity, or until cache management is administratively enabled on the newly-active broker. However, caching services should still be available, since instances that maintained connection to their brokers will provide service while the cache management service is being restored.</p>
    <p class="GraphicCaption">Active/Standby Model</p>
    <p class="GraphicCaption">
      <img src="Images/Solcache_active_standby.png" style="width: 521px;height: 323px;" alt=""/>
    </p>
    <p>The <b>active/active redundancy model</b> is the preferred solution when using the PubSub+ appliance, but is not supported in the software broker, and is not supported when using Dynamic Message Routing (DMR) to interconnect the brokers into an event mesh. While this approach is still subject to potential message loss at the moment of broker failure (just like any other redundancy model involving Direct messaging), it does have the advantage of having a subset of the cache instances maintaining a connection to a broker at all times. The HA mate broker and its associated cache instance(s) will already be online and able to immediately provide caching services to the clients that were previously connected to the failed broker.</p>
    <p>Cache instances are able to immediately re-register with the active Cache Manager  (without administrative intervention) because the Cache Manager availability follows the active broker in an HA pair (presuming stop-on-lost message is disabled and the required configuration is adhered to).   See <MadCap:xref href="Configuring-PubSub-Cache-Ins.htm#Stop-On-Loss">Configuring Stop On Lost Message Behavior</MadCap:xref>) and <b>Active/Active Redundancy Model</b> configuration i in <MadCap:xref href="#Config-Summary">Configuration Summary</MadCap:xref>.</p>
    <p MadCap:conditions="Default.HideFromAllOutput">Prior to 10.0.01, any cache instances needing to restore a connection and registration to the cache cluster will be unable to do so until the failed broker comes back online and takes activity. However, caching services should still be available, since instances that maintained connection to their brokers will provide service while the cache management service is being restored. </p>
    <p> </p>
    <p class="GraphicCaption">Active/Active Redundancy Model</p>
    <p class="GraphicCaption">
      <img src="Images/Solcache_active_active.png" style="width: 528px;height: 327px;" alt=""/>
    </p>
    <h2 class="with-rule"><a name="Config-Summary"/>Configuration Summary</h2>
    <p>
      <b>Active/Standby Redundancy Model (Software Brokers or Appliances)</b>
    </p>
    <ul>
      <li>Appliances should have <code>auto-revert</code> disabled. For more information, see <MadCap:xref href="../../Features/HA-Redundancy/Configuring-Appliance-Redundancy-Parameters.htm">Configuring Redundancy Parameters</MadCap:xref>. </li>
      <li>Appliances must have their redundancy role configured as <code>primary</code> or <code>backup</code>. For more information, see <MadCap:xref href="../../Features/HA-Redundancy/Configuring-Appliance-Redundancy-Parameters.htm#assign-active-standby-role">Assigning the Active/Standby Role</MadCap:xref>.</li>
      <li>Config-Sync is recommended to ensure <MadCap:variable name="Product-Names.pubsub_cache"/> and client configurations are consistent on both the primary and backup brokers. </li>
      <li>Both cache instances shown must be configured as part of the same cache cluster and belonging to a single distributed cache.</li>
      <li>When connection is to the software broker, each cache instance <code>SESSION_HOST</code> configuration property must specify the IP or hostname of both the active and backup broker (comma delimited).</li>
      <li MadCap:conditions="Default.HideFromAllOutput">
        <p>Prior to 10.0.1 Within each message VPN, the cache management function should be enabled on <b>only one</b>broker within the mesh. This becomes a strict requirement when there is Multi-Node Routing (MNR) connectivity between two (or more) brokers that could simultaneously have the cache management function enabled.</p>
        <p>The only configuration where the cache management function is allowed to be enabled simultaneously on multiple brokers, for the same VPN, within the same mesh, is for an active/standby HA pair of brokers that have no MNR connectivity between them. In this situation, and this situation only, the cache management function should be enabled on both brokers in the HA pair.</p>
      </li>
    </ul>
    <p class="Note">In the event of a failover, no administrative action is required if stop-on-lost message is disabled on all cache instances.  If that is not the case, an administrator will need to restart each of the affected cache instances.</p>
    <p>
      <b>Active/Active Redundancy Model (Appliances with MNR or VPN-Bridged Event Mesh)</b>
    </p>
    <ul>
      <li>The brokers should be configured as a non-revertive redundant pair.</li>
      <li>Config-Sync is recommended to ensure <MadCap:variable name="Product-Names.pubsub_cache"/> and client configurations are consistent on both  brokers.</li>
      <li>An MNR neighbor connection must be configured between the brokers in the redundant pair. However, because this is an in-data-center LAN connection, it should be assigned a very low cost (Solace recommends assigning a link cost of 1).</li>
      <li>Export subscriptions must be enabled on the Message VPN hosting the Distributed Cache.</li>
      <li>Both cache instances shown must be configured as part of the same cache cluster and belonging to a single distributed cache.</li>
      <li>Each cache instance <code>SESSION_HOST</code> configuration property must specify the IP of both pairs in the broker (comma delimited), with each instance specifying a different broker in the pair as its first choice.</li>
      <li MadCap:conditions="Default.HideFromAllOutput">
        <p>Prior to 10.0.1, on only one of the brokers,<code> distributed-cache-management</code> must be enabled on the Message VPN hosting the distributed cache. Solace recommends enabling the distributed-cache-management service on the primary broker (Region1-PDC-Primary) and disabling <code>distributed-cache-management</code> on the backup broker (Region-1-PDC-Backup).</p>
      </li>
    </ul>
    <h2 class="with-rule"><a name="After-Failover"/>What to Do After Redundancy Failovers</h2>
    <p>If one broker in the HA pair fails or is taken offline, the remaining broker will take activity and provide service for the affected publishers and subscribers.  Those clients will reconnect and have access to <MadCap:variable name="Product-Names.pubsub_cache"/> and all cached data that was published prior the failover through the <MadCap:variable name="Product-Names.pubsub_cache"/> instances that retained connectivity with the event mesh.  Any cache instances connected directly to the failed or offline broker will need to re-establish connection to the event mesh.</p>
    <p class="Note">Any published data that was in the process of delivery at the time of the failure may be lost, and may not be available in the <MadCap:variable name="Product-Names.pubsub_cache"/> instances on the backup broker. </p>
    <p>The <MadCap:variable name="Product-Names.pubsub_cache"/> instances that lost connectivity due to the failure will connect to the alternative broker and immediately resume service without administrator intervention if they are configured with <code>stop-on-lost-message</code> disabled. This will result in each of those cache instances reporting a Lost Message state. For more information, including instructions on how to clear this state, refer to <MadCap:xref href="Monitoring-PubSub-Cache-Conf.htm#Lost-Msg-State">Lost Message State</MadCap:xref>.</p>
    <p><MadCap:variable name="Product-Names.pubsub_cache"/> instances that lost connectivity and are configured with <code>stop-on-lost-message</code> enabled will require intervention to restore cache function.  Those instances will need to be restarted by following the procedure outlined in the previous section.</p>
    <p MadCap:conditions="Default.HideFromAllOutput">For release prior to 10.0.1, depending on the deployment model chosen, administrative action may be required to restore &lt;code&gt;distributed-cache-management&lt;/code&gt; for the cache.  Specifically, when using active/active redundancy and the failing broker is configured with &lt;code&gt;distributed-cache-management&lt;/code&gt; enabled, you have two options:</p>
    <ul MadCap:conditions="Default.HideFromAllOutput">
      <li>If the duration of the outage is expected to be short, you may choose to wait for the distributed cache manager function to resume with the recovery of the failed broker.  In the interim, any cache instances currently in the <code>Up</code> state will continue providing caching service.  However, new cache instances will be unable to register with the distributed cache during this period.</li>
      <li>Alternatively, the backup broker can take over the cache management function if you enable <code>distributed-cache-management</code> on the surviving broker.  Note that<code> distributed-cache-management</code> for a Message VPN should  only ever be enabled on one broker.  As a result, you should disable it once the failing broker recovers and resumes serving as the cache manager.</li>
    </ul>
  </body>
</html>
